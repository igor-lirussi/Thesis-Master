<!DOCTYPE html>
<html  lang="it"  dir="ltr">

    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <title>Master Thesis - Igor Lirussi</title>
        <link rel="shortcut icon" type="image/png" href="favicon.png">
        <link rel="apple-touch-icon-precomposed" href="apple-touch-icon.png">

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/uikit/2.26.4/css/uikit.gradient.css">

        <link rel="stylesheet" href="style.css">
        <link href="https://vjs.zencdn.net/5.4.4/video-js.css" rel="stylesheet" />
        <script src="https://code.jquery.com/jquery-2.2.1.min.js"></script>
        <script src="./pandoc-uikit/uikit.js"></script>
        <script src="./pandoc-uikit/scripts.js"></script>
        <script src="./pandoc-uikit/jquery.sticky-kit.js"></script>

        <meta name="generator" content="pandoc-uikit" />
                <meta name="author" content="Lirussi Igor" />
                        <meta name="date" content="2023-11-16" />
                <title>Master Thesis - Igor Lirussi</title>
        <style type="text/css">code{white-space: pre;}</style>
                        <style type="text/css">
            pre > code.sourceCode { white-space: pre; position: relative; }
            pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
            pre > code.sourceCode > span:empty { height: 1.2em; }
            .sourceCode { overflow: visible; }
            code.sourceCode > span { color: inherit; text-decoration: inherit; }
            div.sourceCode { margin: 1em 0; }
            pre.sourceCode { margin: 0; }
            @media screen {
            div.sourceCode { overflow: auto; }
            }
            @media print {
            pre > code.sourceCode { white-space: pre-wrap; }
            pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
            }
            pre.numberSource code
              { counter-reset: source-line 0; }
            pre.numberSource code > span
              { position: relative; left: -4em; counter-increment: source-line; }
            pre.numberSource code > span > a:first-child::before
              { content: counter(source-line);
                position: relative; left: -1em; text-align: right; vertical-align: baseline;
                border: none; display: inline-block;
                -webkit-touch-callout: none; -webkit-user-select: none;
                -khtml-user-select: none; -moz-user-select: none;
                -ms-user-select: none; user-select: none;
                padding: 0 4px; width: 4em;
                color: #aaaaaa;
              }
            pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
            div.sourceCode
              {  background-color: #f8f8f8; }
            @media screen {
            pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
            }
            code span.al { color: #ef2929; } /* Alert */
            code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
            code span.at { color: #204a87; } /* Attribute */
            code span.bn { color: #0000cf; } /* BaseN */
            code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
            code span.ch { color: #4e9a06; } /* Char */
            code span.cn { color: #8f5902; } /* Constant */
            code span.co { color: #8f5902; font-style: italic; } /* Comment */
            code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
            code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
            code span.dt { color: #204a87; } /* DataType */
            code span.dv { color: #0000cf; } /* DecVal */
            code span.er { color: #a40000; font-weight: bold; } /* Error */
            code span.ex { } /* Extension */
            code span.fl { color: #0000cf; } /* Float */
            code span.fu { color: #204a87; font-weight: bold; } /* Function */
            code span.im { } /* Import */
            code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
            code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
            code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
            code span.ot { color: #8f5902; } /* Other */
            code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
            code span.sc { color: #ce5c00; font-weight: bold; } /* SpecialChar */
            code span.ss { color: #4e9a06; } /* SpecialString */
            code span.st { color: #4e9a06; } /* String */
            code span.va { color: #000000; } /* Variable */
            code span.vs { color: #4e9a06; } /* VerbatimString */
            code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
        </style>
                        <link rel="stylesheet" href="./pandoc-uikit/uikit.css" />
                                          <script
                                          src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
                                          type="text/javascript"></script>
                               
    </head>

    <body>


        <div class="uk-container uk-container-center uk-margin-top uk-margin-large-bottom">

                        <div class="uk-grid" data-uk-grid-margin>
                <div class="uk-width-1-1">
                    <h1 class="uk-heading">Master Thesis - Igor Lirussi</h1>
                                        <h1 class="uk-heading" style="margin:0">2023-11-16</h1>
                                                            <p class="uk-text-large">Lirussi
Igor</p>
                                    </div>
            </div>
            
            <div class="uk-grid" data-uk-grid-margin >          
                <div class="uk-width-medium-1-4">
                    <div class="uk-overflow-container" data-uk-sticky="{top:25,media: 768}">
                        <div class="uk-panel uk-panel-box menu-begin" >

                                                        <ul>
                                                        <li><a
                                                        href="#fooabstract"
                                                        id="footoc-abstract">Abstract</a></li>
                                                        <li><a
                                                        href="#foosection"
                                                        id="footoc-section"></a></li>
                                                        <li><a
                                                        href="#fooacknowledgements"
                                                        id="footoc-acknowledgements">Acknowledgements</a></li>
                                                        <li><a
                                                        href="#foolist-of-symbols"
                                                        id="footoc-list-of-symbols">List
                                                        of Symbols</a></li>
                                                        <li><a
                                                        href="#foolist-of-acronymsabbreviations"
                                                        id="footoc-list-of-acronymsabbreviations">List
                                                        of
                                                        Acronyms/Abbreviations</a></li>
                                                        <li><a
                                                        href="#foochap:introduction"
                                                        id="footoc-chap:introduction"><span
                                                        class="toc-section-number">1</span>
                                                        Introduction</a>
                                                        <ul>
                                                        <li><a
                                                        href="#foooverview"
                                                        id="footoc-overview"><span
                                                        class="toc-section-number">1.1</span>
                                                        Overview</a></li>
                                                        <li><a
                                                        href="#foochallenges"
                                                        id="footoc-challenges"><span
                                                        class="toc-section-number">1.2</span>
                                                        Challenges</a></li>
                                                        <li><a
                                                        href="#fooobjectives"
                                                        id="footoc-objectives"><span
                                                        class="toc-section-number">1.3</span>
                                                        Objectives</a></li>
                                                        <li><a
                                                        href="#foothesis-structure"
                                                        id="footoc-thesis-structure"><span
                                                        class="toc-section-number">1.4</span>
                                                        Thesis
                                                        Structure</a></li>
                                                        </ul></li>
                                                        <li><a
                                                        href="#foochap:background"
                                                        id="footoc-chap:background"><span
                                                        class="toc-section-number">2</span>
                                                        State of the Art</a>
                                                        <ul>
                                                        <li><a
                                                        href="#foogaussian-processes"
                                                        id="footoc-gaussian-processes"><span
                                                        class="toc-section-number">2.1</span>
                                                        Gaussian
                                                        Processes</a></li>
                                                        <li><a href="#foocnp"
                                                        id="footoc-cnp"><span
                                                        class="toc-section-number">2.2</span>
                                                        CNP</a></li>
                                                        <li><a
                                                        href="#foocnmps"
                                                        id="footoc-cnmps"><span
                                                        class="toc-section-number">2.3</span>
                                                        CNMPs</a></li>
                                                        </ul></li>
                                                        <li><a
                                                        href="#foochap:platforms"
                                                        id="footoc-chap:platforms"><span
                                                        class="toc-section-number">3</span>
                                                        Platforms</a>
                                                        <ul>
                                                        <li><a
                                                        href="#foobaxter-robot"
                                                        id="footoc-baxter-robot"><span
                                                        class="toc-section-number">3.1</span>
                                                        Baxter Robot</a></li>
                                                        <li><a
                                                        href="#foour10-robot"
                                                        id="footoc-ur10-robot"><span
                                                        class="toc-section-number">3.2</span>
                                                        UR10 Robot</a></li>
                                                        <li><a
                                                        href="#foof-robotiq-gripper"
                                                        id="footoc-f-robotiq-gripper"><span
                                                        class="toc-section-number">3.3</span>
                                                        3F Robotiq
                                                        Gripper</a></li>
                                                        <li><a
                                                        href="#fooframeworks"
                                                        id="footoc-frameworks"><span
                                                        class="toc-section-number">3.4</span>
                                                        Frameworks</a></li>
                                                        </ul></li>
                                                        <li><a
                                                        href="#foochap:design"
                                                        id="footoc-chap:design"><span
                                                        class="toc-section-number">4</span>
                                                        Design</a>
                                                        <ul>
                                                        <li><a
                                                        href="#fooend-to-end-concatenation"
                                                        id="footoc-end-to-end-concatenation"><span
                                                        class="toc-section-number">4.1</span>
                                                        End-To-End
                                                        Concatenation</a></li>
                                                        <li><a
                                                        href="#foopartial-combination"
                                                        id="footoc-partial-combination"><span
                                                        class="toc-section-number">4.2</span>
                                                        Partial
                                                        Combination</a></li>
                                                        </ul></li>
                                                        <li><a
                                                        href="#foochap:implementation"
                                                        id="footoc-chap:implementation"><span
                                                        class="toc-section-number">5</span>
                                                        Implementation</a></li>
                                                        <li><a
                                                        href="#foochap:validation"
                                                        id="footoc-chap:validation"><span
                                                        class="toc-section-number">6</span>
                                                        Validation and
                                                        Testing</a></li>
                                                        <li><a
                                                        href="#foochap:conclusions"
                                                        id="footoc-chap:conclusions"><span
                                                        class="toc-section-number">7</span>
                                                        Conclusions</a>
                                                        <ul>
                                                        <li><a
                                                        href="#foofuture-work"
                                                        id="footoc-future-work"><span
                                                        class="toc-section-number">7.1</span>
                                                        Future work</a></li>
                                                        </ul></li>
                                                        </ul>
                            
                        </div>
                    </div>
                </div>

                <div class="uk-width-medium-3-4">
<div class="titlepage">
<div class="center">
<p><strong>ALMA MATER STUDIORUM &#x2013; UNIVERSITY OF BOLOGNA<br />
CESENA CAMPUS</strong><br />
</p>
<p>School of Engineering and Architecture<br />
Second Cycle Degree/Two-year Master in<br />
Computer Science and Engineering</p>
<p><strong>Novel high-level skill generation<br />
in robotics by combining movement primitives<br />
learned by CNMP models</strong></p>
<p>Master&#x2019;s thesis in<br />
<span class="smallcaps">Intelligent Robotic Systems</span></p>
<div class="flushleft">
<p><em>Supervisor</em><br />
<strong>Prof.</strong> <strong>Andrea Roli</strong><br />
<em>Co-Supervisor</em><br />
<strong>Prof.</strong> <strong>Emre U&#x11F;ur</strong><br />
(Bo&#x11F;azi&#xE7;i University, Istanbul)</p>
</div>
<div class="flushright">
<p><em>Candidate</em><br />
<strong>Igor Lirussi</strong></p>
</div>
<p><br />
</p>
<p>Academic Year 2022-2023</p>
</div>
</div>
<section id="fooabstract" class="level1 unnumbered">
<h1 class="unnumbered">Abstract</h1>
<p>Max 2000 characters, strict. UniBo has that limit in the upload system!
Will write at the end.</p>
</section>
<section id="foosection" class="level1 unnumbered">
<h1 class="unnumbered"></h1>
<div class="flushright">
<p><em>Dedication here</em></p>
</div>
</section>
<section id="fooacknowledgements" class="level1 unnumbered">
<h1 class="unnumbered">Acknowledgements</h1>
<p>Acknowledgments here.</p>
</section>
<section id="foolist-of-symbols" class="level1 unnumbered">
<h1 class="unnumbered">List of Symbols</h1>
<div class="tabbing">
<p>&#x304;&#x304;</p>
<p><span class="math inline">\(a_{ij}\)</span></p>
<p>Description of <span class="math inline">\(a_{ij}\)</span></p>
<p><br />
<span class="math inline">\(\mathbf{A}\)</span></p>
<p>State transition matrix of a hidden Markov model</p>
<p><br />
<span class="math inline">\(t\)</span></p>
<p>Time</p>
<p><br />
</p>
<p><br />
<span class="math inline">\(\alpha\)</span></p>
<p>Blending parameter <em>or</em> scale</p>
<p><br />
<span class="math inline">\(\beta_t(i)\)</span></p>
<p>Backward variable</p>
<p><br />
<span class="math inline">\(\Theta\)</span></p>
<p>Parameter set</p>
<p><br />
<span class="math inline">\(\sigma\)</span></p>
<p>Standard Deviation</p>
<p><br />
<span class="math inline">\(\mu\)</span></p>
<p>Mean</p>
<p><br />
</p>
</div>
</section>
<section id="foolist-of-acronymsabbreviations" class="level1 unnumbered">
<h1 class="unnumbered">List of Acronyms/Abbreviations</h1>
<div class="tabbing">
<p>&#x304;&#x304;</p>
<p>2D</p>
<p>Two Dimensional</p>
<p><br />
3D</p>
<p>Three Dimensional</p>
<p><br />
IR</p>
<p>Infrared</p>
<p><br />
ROS</p>
<p>Robot Operating System</p>
<p><br />
RGB</p>
<p>Red Green Blue</p>
<p><br />
RGBD</p>
<p>Red Green Blue Depth</p>
<p><br />
GP</p>
<p>Gaussian Processes</p>
<p><br />
CNP</p>
<p>Conditional Neural Processes</p>
<p><br />
CNMP</p>
<p>Conditional Neural Movement Primitives</p>
<p><br />
YOLO</p>
<p>You Only Look Once model</p>
<p><br />
</p>
</div>
</section>
<section id="foochap:introduction" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span>
Introduction</h1>
<section id="foooverview" class="level2" data-number="1.1">
<h2 data-number="1.1"><span class="header-section-number">1.1</span>
Overview</h2>
<p>Humans have a remarkable ability to achieve complex goals in a wide variety
of tasks. A person is usually exposed to different scenarios during the day,
starting from the home environment to the commute, work, mealtime, and so on.
The versatility of our species is a key factor, and the human cognitive
flexibility has been appointed as a major driver in evolution <span
class="citation" data-cites="deak2003development">(Deak 2003)</span>, <span
class="citation" data-cites="karmiloff1994beyond">(Karmiloff-Smith
1994)</span>. Some situations are more complicated than others; nevertheless,
regardless of their difference, humans excel in meeting the different demands
to solve the tasks desired.</p>
<p>All these scenarios present different small challenges to solve in order to
accomplish the desired high-level goal. Humans switch contexts in a really
flexible and natural way and constantly take care of the multitude of these
small problems that are faced to complete the desired objective. For example,
a general task can be divided into subtasks, which can then be further divided
into smaller ones <span class="citation"
data-cites="kroemer2021review">(Kroemer, Niekum, e Konidaris 2021)</span>. The
strategy of breaking down intricate objectives into smaller, manageable,
simpler activities is the most widely used heuristic to solve problems <span
class="citation" data-cites="egidi2006decomposition">(Egidi 2006)</span>.</p>
<p>Many of these sub-challenges require an interaction with one or more
objects. For example, the action of opening involves a door to pass through it
while moving or to access the fridge for cooking. The reaching action can
imply an object like a pen in the office to write or a glass of water to
drink. To push as an action often implies a button to enable a device in the
workplace, or to turn on a car to commute, or the stove to heat a meal.
Objects have undoubtedly strong importance in the small actions performed to
achieve a goal, and their affordance is still the object of research in humans
<span class="citation" data-cites="maranesi2014cortical">(Maranesi, Bonini, e
Fogassi 2014)</span>, <span class="citation"
data-cites="osiurak2017affordance">(Osiurak, Rossetti, e Badets 2017)</span>
and machines <span class="citation"
data-cites="horton2012affordances">(Horton, Chakraborty, e Amant
2012)</span>.</p>
<p>As seen, many different movements and sub-actions, often involving objects,
are executed in daily life. Furthermore, they are also adapted to accomplish
the current desired goals. The adaptation can involve a simple difference of
position with respect to the previous location, both of the object or the
executor, or can involve a completely different context to which the action
learned is transferred. These skills are learned and discovered at the
beginning, and then the knowledge of the action is abstracted and adapted to
different purposes.</p>
<p>Moreover, a person builds sequences of actions naturally to achieve the
objective and, as discussed, adapts them to the environment. The skills are
often combined together one after the other, based on the scenario but also
based on the result and position of the previous execution. Occasionally, it
can happen that part of an action is used and part of another action, mixing
previously learned movements if the situation requires it. This results in the
creation of new combinations and compositions of previously known
activities.</p>
<p>Lastly, dissecting complex challenges requires also decision-making under
uncertainty, which is essential for achieving high-level goals since the
sequence of activities is not always clear in advance. Often, the goal changes
mid-way in response to the environment, or the initial assessment is
sub-optimal or incorrect, forcing a change in planning and a new decision on
what subsequent action to take. So it&#x2019;s worth noting that online decision
under dynamic circumstances and change of skill executed allows a person to
navigate the complexities of daily scenarios with success.</p>
<p>The human mind&#x2019;s capacity for abstraction, planning, and execution is still
a remote objective for robotics <span class="citation"
data-cites="konidaris2019necessity">(Konidaris 2019)</span>. This level of
adaptation to the environment and building of compounded behaviors is still a
hard challenge to solve nowadays.</p>
<p>For this reason, robots currently are not pervasive in society like other
technologies. Humanoid robots have little if no presence and, despite the
potential different uses, are relegated to mainly interaction and exhibition
duties. The majority of robots work in a controlled environment, like
factories, where the surroundings are specifically designed for them. The
actions taken are repetitive, fixed, and in contact with a simple, defined set
of objects.</p>
<p>Furthermore, even if some robots are able to integrate into semi-structured
environments (for example, the robotic vacuum cleaners for homes or lawnmowers
for gardens), they are specialized to a single task in a single scenario.
Multi-purpose robots require a more human-compatible design and a higher
degree of intelligent behavior <span class="citation"
data-cites="dechant2021toward">(DeChant e Bauer 2021)</span>, but versatile
humanoid robots are still not pervasive in the current status of society.</p>
<p>In this study, we propose a computational model that is biologically
inspired. Our approach consists of the use of mathematics and artificial
intelligence to emulate human abstraction and adaptation capabilities in the
execution of a series of primitive actions. We want to prove how demonstrating
basic movements to a robot and composing them together with flexibility may
lead to achieving complex tasks of various natures. Specifically, movement
primitives are reused and combined differently for different goals, avoiding
explicit teaching of multiple objectives. The trajectories for the skills
learned are adapted to the environment and partially composed thanks to the
interpolation abilities of Conditional Neural Movement Primitives (CNMP)
networks <span class="citation" data-cites="Ugur-RSS-19">(Ugur 2019)</span>.
Lastly, the approach has been implemented and tested on an anthropomorphic
robot and on an industrial collaborative robot.</p>
</section>
<section id="foochallenges" class="level2" data-number="1.2">
<h2 data-number="1.2"><span class="header-section-number">1.2</span>
Challenges</h2>
<p>Robotics dominates many fields, but as discussed, often the environment is
controlled, designed to help the robot in its task, and not human-friendly. If
the purpose is to integrate robots into the human environment, robots must
adapt to humans, not vice-versa. All environments in which humans are present
are not organized or predictable, and this means one issue is that robots have
to accommodate for these conditions. A challenge is definitely to introduce
the machine to an unstructured environment, and this implies many
sub-issues.</p>
<p>Having surroundings that might change forces the machines to have a great
amount of perception. The system has to be extremely aware of the objects and
people around it to operate in a safe and meaningful way. This translates into
equipping many sensors and using real-time data from all available sources.
Moreover, the machine cannot rely on these detection instruments mounted on
the external world since a humanoid robot is expected to be mobile. Having a
multi-purpose system that can act in different scenarios implies, indeed, a
self-contained arrangement of sensors.</p>
<p>The perception brings, in cascade, the necessity of storing this
information and creating an internal copy of the surroundings that works as a
base for planning and future predictions. Creating a digital twin for the
environment is not essential for all the actions since some of them can be
executed in real-time, but it is required to plan their effects and combine
results together. For example, if a sponge is needed to clean a table, it
would be faster to have the knowledge of its last position, but it can also be
researched on demand and used while observing the effects in real-time till
the table is clean. On the other hand, complex actions that combine multiple
primitives need a future prediction of their effects on the environment, so
its internal representation is required.</p>
<p>With changing surroundings, it is possible also that the expected position
of objects is no longer consistent with the representation. This forces the
system to find an alternative or explore the environment till the object is
found. Other kinds of exploration possible are the exploration of the action
space to infer new actions and results, or the exploration of objects&#x2019;
capabilities to learn new affordances and usages. <span class="citation"
data-cites="Ahmetoglu_2022">(Ahmetoglu et al. 2022)</span></p>
<p>Another factor worth taking into consideration is the planning subject.
Plans have to be structured in a meaningful way otherwise, an incorrect
sequence won&#x2019;t just produce an incorrect result but might bring the system
further away from the final goal. The combinations of actions generated
usually have importance in the order of execution, so the product of the
skills has to be considered carefully.</p>
<p>Furthermore, objects and tools are usually designed for humans, so their
capabilities might vary depending on the machine used and might influence the
actions in the planning phase. Giving meanings to the objects, both in terms
of affordances and representations, is still a tricky challenge in robotics
and partially involves the previously investigated challenges of planning and
exploration.</p>
<p>Also, obstacle avoidance, whenever there is an object in the trajectory of
movement, is a factor to take into consideration. The robot is required to be
aware of the surroundings and itself, not to collide, hurt, damage, or just
fail the designated goal. Humans adapt previously known actions whenever an
obstacle or an impediment is present.</p>
<p>Part of the adaptation challenge is also being able to transfer the skills
known to new locations and scenarios. For example, learning how to turn a key
for the door and use the action for the key of the car or the knob to turn on
the stove. This is an essential capability that is difficult to implement in a
machine.</p>
<p>Another more hidden challenge is how the actions are merged among them.
Usually, humans, when they pass from one action to another, apply a smooth
transition. This means that the movements don&#x2019;t have to fully start and end as
they are learned, or the result will be artificial and sub-optimal.</p>
<p>Furthermore, object handling, grasping, and manipulation present some
issues that are the object of research. How to pick the item desired, where,
with which grasp, and with which force intensity are issues that can undermine
the final result.</p>
<p>Lastly, another challenge that will be encountered is the recognition when
the action is completed. Being aware of the right final state is essential for
successfully matching the expectations for the goal requested.</p>
<p>These challenges discussed are crucial aspects to consider, but not all of
them will be addressed in this project, and some will also be simplified.
Nevertheless, it&#x2019;s worth noting the scope and limitations of this work and the
boundaries within which the research operates.</p>
</section>
<section id="fooobjectives" class="level2" data-number="1.3">
<h2 data-number="1.3"><span class="header-section-number">1.3</span>
Objectives</h2>
<p>The aim of this research is to investigate novel skill generation by
combining previously taught ones with the use of CNMPs. The research aims to
be applied to robotics scenarios involving trajectories for object
manipulation and high-level goal achievement. The generation of new
combinations of skills will be performed by connecting skill segments that the
robot learned by demonstration. The amount of demonstrations given should be
reasonable for the system to be applied in real life by a human. The
combination of actions will be investigated in both the concatenation of
trajectories end-to-end and the use of parts of them. The ultimate goal is to
create a system that allows a robot, given some demonstrations, to reuse the
skills acquired to complete different objectives whose trajectories were never
taught explicitly. Furthermore, the adaptation should ideally be acceptable in
different configurations of the environment and ideally in different
scenarios.</p>
</section>
<section id="foothesis-structure" class="level2" data-number="1.4">
<h2 data-number="1.4"><span class="header-section-number">1.4</span> Thesis
Structure</h2>
<p>Accordingly, the remainder of this thesis is structured as follows.</p>
<p>discusses the background of the topic, the current advancements in the
field, and the related research with a literature review.</p>
<p>In <a href="#foochap:platforms" data-reference-type="ref"
data-reference="chap:platforms">3</a> the instruments and frameworks used in
this research are listed and analyzed to be able to understand the initial
setup and replicate the results.</p>
<p>The <a href="#foochap:design" data-reference-type="ref"
data-reference="chap:design">4</a> explains the design and architecture of the
proposed method. In order to understand the logic, the conceptual passages and
mathematical background.</p>
<p>The <a href="#foochap:implementation" data-reference-type="ref"
data-reference="chap:implementation">5</a> analyzes the key points of the
implemented solution through the explanation of the most important passages in
the code developed.</p>
<p>The <a href="#foochap:validation" data-reference-type="ref"
data-reference="chap:validation">6</a> shows the final results and the testing
on real-life robotic platforms.</p>
<p>Finally, concludes this thesis by summarising its main contribution and
future work.</p>
</section>
</section>
<section id="foochap:background" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> State of the
Art</h1>
<p>Key challenge is creating robots that are capable of directly interacting
with the world around them and robot manipulation is central in this. <span
class="citation" data-cites="kroemer2021review">(Kroemer, Niekum, e Konidaris
2021)</span></p>
<p>The ability to solve high level goals in robot is increasing <span
class="citation" data-cites="gupta2019relay">(Gupta et al. 2019)</span>, <span
class="citation" data-cites="simeonov2021long">(Simeonov et al. 2021)</span>
thanks to ...</p>
<p>Some may follow natural language instructions <span class="citation"
data-cites="hu2019hierarchical">(Hu et al. 2019)</span> Gaussian processes are
used in ML <span class="citation" data-cites="seeger2004gaussian">(Seeger
2004)</span> For instance in <span class="citation"
data-cites="Ugur-RSS-19">(Ugur 2019)</span> the authors propose a novel ...
And in <span class="citation"
data-cites="DBLP:journals/corr/abs-1807-01613">(Garnelo et al. 2018)</span> we
can find Conditional Neural Processes.</p>
<section id="foogaussian-processes" class="level2" data-number="2.1">
<h2 data-number="2.1"><span class="header-section-number">2.1</span> Gaussian
Processes</h2>
</section>
<section id="foocnp" class="level2" data-number="2.2">
<h2 data-number="2.2"><span class="header-section-number">2.2</span> CNP</h2>
</section>
<section id="foocnmps" class="level2" data-number="2.3">
<h2 data-number="2.3"><span class="header-section-number">2.3</span>
CNMPs</h2>
<p>Description in detail of CNMP work Allows to learn skills in tens,
ratherthousands, of real-world interactions</p>
</section>
</section>
<section id="foochap:platforms" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span>
Platforms</h1>
<section id="foobaxter-robot" class="level2" data-number="3.1">
<h2 data-number="3.1"><span class="header-section-number">3.1</span> Baxter
Robot</h2>
<figure id="foofig:baxter">
<img src="Images/baxter.png" />
<figcaption>Baxter Robot platform</figcaption>
</figure>
</section>
<section id="foour10-robot" class="level2" data-number="3.2">
<h2 data-number="3.2"><span class="header-section-number">3.2</span> UR10
Robot</h2>
<figure id="foofig:ur10">
<img src="Images/ur10.png" />
<figcaption>UR10 Robot platform</figcaption>
</figure>
</section>
<section id="foof-robotiq-gripper" class="level2" data-number="3.3">
<h2 data-number="3.3"><span class="header-section-number">3.3</span> 3F
Robotiq Gripper</h2>
<figure id="foofig:gripper3f">
<img src="Images/gripper3f.png" />
<figcaption>3F Robotiq Gripper platform</figcaption>
</figure>
</section>
<section id="fooframeworks" class="level2" data-number="3.4">
<h2 data-number="3.4"><span class="header-section-number">3.4</span>
Frameworks</h2>
<section id="fooros" class="level5" data-number="3.4.0.0.1">
<h5 data-number="3.4.0.0.1"><span
class="header-section-number">3.4.0.0.1</span> ROS</h5>
</section>
<section id="foopytorch" class="level5" data-number="3.4.0.0.2">
<h5 data-number="3.4.0.0.2"><span
class="header-section-number">3.4.0.0.2</span> Pytorch</h5>
</section>
<section id="foojupyter-notebook" class="level5" data-number="3.4.0.0.3">
<h5 data-number="3.4.0.0.3"><span
class="header-section-number">3.4.0.0.3</span> Jupyter Notebook</h5>
</section>
</section>
</section>
<section id="foochap:design" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> Design</h1>
<p>Intro to the combination of trajectories</p>
<section id="fooend-to-end-concatenation" class="level2" data-number="4.1">
<h2 data-number="4.1"><span class="header-section-number">4.1</span>
End-To-End Concatenation</h2>
</section>
<section id="foopartial-combination" class="level2" data-number="4.2">
<h2 data-number="4.2"><span class="header-section-number">4.2</span> Partial
Combination</h2>
<figure id="foofig:classes">
<embed src="figures/classes.pdf" />
<figcaption>A class diagram created with PlantUML</figcaption>
</figure>
<p>You may want to reference images in your thesis. In this case, you are
encouraged to make them <em>floating</em>, and reference them by means of
labels. For instance, in , we describe a class diagram produced by means of <a
href="http://plantuml.com">PlantUML</a>.</p>
</section>
</section>
<section id="foochap:implementation" class="level1" data-number="5">
<h1 data-number="5"><span class="header-section-number">5</span>
Implementation</h1>
<p>Write implementation here.</p>
<div class="sourceCode" id="foolst:pieceofcode" data-float=""
data-language="Java" data-caption="A piece of code"
label="lst:pieceofcode"><pre class="sourceCode java"><code class="sourceCode java"><span id="foolst:pieceofcode-1"><a href="#foolst:pieceofcode-1" aria-hidden="true" tabindex="-1"></a><span class="kw">public</span> <span class="kw">class</span> HelloWorld <span class="op">{</span></span>
<span id="foolst:pieceofcode-2"><a href="#foolst:pieceofcode-2" aria-hidden="true" tabindex="-1"></a>  <span class="kw">public</span> <span class="dt">static</span> <span class="dt">void</span> <span class="fu">main</span><span class="op">(</span><span class="bu">String</span><span class="op">[]</span> args<span class="op">)</span> <span class="op">{</span></span>
<span id="foolst:pieceofcode-3"><a href="#foolst:pieceofcode-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Prints &quot;Hello, World&quot; to the terminal window.</span></span>
<span id="foolst:pieceofcode-4"><a href="#foolst:pieceofcode-4" aria-hidden="true" tabindex="-1"></a>    <span class="bu">System</span><span class="op">.</span><span class="fu">out</span><span class="op">.</span><span class="fu">println</span><span class="op">(</span><span class="st">&quot;Hello, World&quot;</span><span class="op">);</span></span>
<span id="foolst:pieceofcode-5"><a href="#foolst:pieceofcode-5" aria-hidden="true" tabindex="-1"></a>  <span class="op">}</span></span>
<span id="foolst:pieceofcode-6"><a href="#foolst:pieceofcode-6" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
<p>You may need to reference listings in your thesis. In this case, you are
encouraged to make them <em>floating</em>, and reference them by means of
labels. For instance, in , we describe an hello world program in Java.</p>
</section>
<section id="foochap:validation" class="level1" data-number="6">
<h1 data-number="6"><span class="header-section-number">6</span> Validation
and Testing</h1>
<p>Result validation and testing on real-life robots here</p>
</section>
<section id="foochap:conclusions" class="level1" data-number="7">
<h1 data-number="7"><span class="header-section-number">7</span>
Conclusions</h1>
<p>Humans are capable of executing a wide variety of complex actions, based on
prior experience. In this thesis, we provided a possible approach to novel
high-level skill generation by combining movement primitives learned by CNMP
models.</p>
<section id="foofuture-work" class="level2" data-number="7.1">
<h2 data-number="7.1"><span class="header-section-number">7.1</span> Future
work</h2>
<p>Possible future works are ...</p>
<div id="foorefs" class="references csl-bib-body hanging-indent" role="list">
<div id="fooref-Ahmetoglu_2022" class="csl-entry" role="listitem">
Ahmetoglu, Alper, M. Yunus Seker, Justus Piater, Erhan Oztop, e Emre Ugur.
2022. <span>&#xAB;DeepSym: Deep Symbol Generation and Rule Learning for Planning
from Unsupervised Robot Interaction&#xBB;</span>. <em>Journal of Artificial
Intelligence Research</em> 75 (novembre): 709&#x2013;45. <a
href="https://doi.org/10.1613/jair.1.13754">https://doi.org/10.1613/jair.1.13754</a>.
</div>
<div id="fooref-deak2003development" class="csl-entry" role="listitem">
Deak, Gedeon O. 2003. <span>&#xAB;The development of cognitive flexibility and
language abilities&#xBB;</span>. <em>Advances in child development and
behavior</em> 31: 273&#x2013;328.
</div>
<div id="fooref-dechant2021toward" class="csl-entry" role="listitem">
DeChant, Chad, e Daniel Bauer. 2021. <span>&#xAB;Toward robots that learn to
summarize their actions in natural language: a set of tasks&#xBB;</span>. In
<em>5th Annual Conference on Robot Learning, Blue Sky Submission Track</em>.
<a
href="https://openreview.net/forum?id=n3AW_ISWCXf">https://openreview.net/forum?id=n3AW_ISWCXf</a>.
</div>
<div id="fooref-egidi2006decomposition" class="csl-entry" role="listitem">
Egidi, Massimo. 2006. <span>&#xAB;Decomposition patterns in problem
solving&#xBB;</span>. <em>Contributions to Economic Analysis</em> 280: 15&#x2013;46.
</div>
<div id="fooref-DBLP:journals/corr/abs-1807-01613" class="csl-entry"
role="listitem">
Garnelo, Marta, Dan Rosenbaum, Chris J. Maddison, Tiago Ramalho, David Saxton,
Murray Shanahan, Yee Whye Teh, Danilo J. Rezende, e S. M. Ali Eslami. 2018.
<span>&#xAB;Conditional Neural Processes&#xBB;</span>. <em>CoRR</em> abs/1807.01613. <a
href="http://arxiv.org/abs/1807.01613">http://arxiv.org/abs/1807.01613</a>.
</div>
<div id="fooref-gupta2019relay" class="csl-entry" role="listitem">
Gupta, Abhishek, Vikash Kumar, Corey Lynch, Sergey Levine, e Karol Hausman.
2019. <span>&#xAB;Relay Policy Learning: Solving Long-Horizon Tasks via Imitation
and Reinforcement Learning&#xBB;</span>. <a
href="https://arxiv.org/abs/1910.11956">https://arxiv.org/abs/1910.11956</a>.
</div>
<div id="fooref-horton2012affordances" class="csl-entry" role="listitem">
Horton, Thomas E, Arpan Chakraborty, e Robert St Amant. 2012.
<span>&#xAB;Affordances for robots: a brief survey&#xBB;</span>. <em>AVANT. Pismo
Awangardy Filozoficzno-Naukowej</em> 2: 70&#x2013;84.
</div>
<div id="fooref-hu2019hierarchical" class="csl-entry" role="listitem">
Hu, Hengyuan, Denis Yarats, Qucheng Gong, Yuandong Tian, e Mike Lewis. 2019.
<span>&#xAB;Hierarchical decision making by generating and following natural
language instructions&#xBB;</span>. <em>Advances in neural information processing
systems</em> 32.
</div>
<div id="fooref-karmiloff1994beyond" class="csl-entry" role="listitem">
Karmiloff-Smith, By A. 1994. <span>&#xAB;Beyond modularity: A developmental
perspective on cognitive science&#xBB;</span>. <em>European journal of disorders of
communication</em> 29 (1): 95&#x2013;105.
</div>
<div id="fooref-konidaris2019necessity" class="csl-entry" role="listitem">
Konidaris, George. 2019. <span>&#xAB;On the necessity of abstraction&#xBB;</span>.
<em>Current opinion in behavioral sciences</em> 29: 1&#x2013;7.
</div>
<div id="fooref-kroemer2021review" class="csl-entry" role="listitem">
Kroemer, Oliver, Scott Niekum, e George Konidaris. 2021. <span>&#xAB;A review of
robot learning for manipulation: Challenges, representations, and
algorithms&#xBB;</span>. <em>The Journal of Machine Learning Research</em> 22 (1):
1395&#x2013;1476.
</div>
<div id="fooref-maranesi2014cortical" class="csl-entry" role="listitem">
Maranesi, Monica, Luca Bonini, e Leonardo Fogassi. 2014. <span>&#xAB;Cortical
processing of object affordances for self and others&#x2019; action&#xBB;</span>.
<em>Frontiers in psychology</em> 5: 538.
</div>
<div id="fooref-osiurak2017affordance" class="csl-entry" role="listitem">
Osiurak, Fran&#xE7;ois, Yves Rossetti, e Arnaud Badets. 2017. <span>&#xAB;What is an
affordance? 40 years later&#xBB;</span>. <em>Neuroscience &amp; Biobehavioral
Reviews</em> 77: 403&#x2013;17.
</div>
<div id="fooref-seeger2004gaussian" class="csl-entry" role="listitem">
Seeger, Matthias. 2004. <span>&#xAB;Gaussian processes for machine
learning&#xBB;</span>. <em>International journal of neural systems</em> 14 (02):
69&#x2013;106.
</div>
<div id="fooref-simeonov2021long" class="csl-entry" role="listitem">
Simeonov, Anthony, Yilun Du, Beomjoon Kim, Francois Hogan, Joshua Tenenbaum,
Pulkit Agrawal, e Alberto Rodriguez. 2021. <span>&#xAB;A long horizon planning
framework for manipulating rigid pointcloud objects&#xBB;</span>. In <em>Conference
on Robot Learning</em>, 1582&#x2013;1601. PMLR.
</div>
<div id="fooref-Ugur-RSS-19" class="csl-entry" role="listitem">
Ugur, Muhammet Yunus Seker AND Mert Imre AND Justus Piater AND Emre. 2019.
<span>&#xAB;Conditional Neural Movement Primitives&#xBB;</span>. In <em>Proceedings of
Robotics: Science and Systems</em>. FreiburgimBreisgau, Germany. <a
href="https://doi.org/10.15607/RSS.2019.XV.071">https://doi.org/10.15607/RSS.2019.XV.071</a>.
</div>
</div>
</section>
</section>                    
                </div>
            </div>

</script>
            <script src="https://vjs.zencdn.net/5.4.4/video.js"></script>
        </div>
    </body>
</html>
